{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "890aeb1c",
   "metadata": {},
   "source": [
    "6.The df.describe() method provides the 'count', 'mean', 'std', 'min', '25%', '50%', '75%', and 'max' summary statistics for each variable it analyzes. Give the definitions (perhaps using help from the ChatBot if needed) of each of these summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e18a58f",
   "metadata": {},
   "source": [
    "The `df.describe()` method in pandas provides summary statistics for each numerical column in a DataFrame. Below are the definitions for each statistic it returns:\n",
    "\n",
    "1. **Count**: \n",
    "   - The number of non-null (non-missing) values for each variable.\n",
    "\n",
    "2. **Mean**:\n",
    "   - The arithmetic average of the values. It is calculated as the sum of all values divided by the number of values.\n",
    "   - Formula: \\(\\text{Mean} = \\frac{\\sum{x}}{n}\\)\n",
    "\n",
    "3. **Standard Deviation (std)**:\n",
    "   - A measure of how spread out the values are around the mean. It shows the average distance between each value and the mean.\n",
    "   - Formula: \\(\\text{Standard Deviation} = \\sqrt{\\frac{1}{n}\\sum(x_i - \\bar{x})^2}\\), where \\(\\bar{x}\\) is the mean.\n",
    "\n",
    "4. **Minimum (min)**:\n",
    "   - The smallest value in the dataset.\n",
    "\n",
    "5. **25% (First Quartile)**:\n",
    "   - The value below which 25% of the data points fall. It is also known as the first quartile (Q1).\n",
    "\n",
    "6. **50% (Median)**:\n",
    "   - The middle value of the dataset when ordered from lowest to highest. This is the second quartile (Q2) and is also called the median.\n",
    "\n",
    "7. **75% (Third Quartile)**:\n",
    "   - The value below which 75% of the data points fall. It is also known as the third quartile (Q3).\n",
    "\n",
    "8. **Maximum (max)**:\n",
    "   - The largest value in the dataset.\n",
    "\n",
    "Together, these summary statistics provide a good understanding of the central tendency, dispersion, and spread of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482f8ed0",
   "metadata": {},
   "source": [
    "Missing data can be considered \"across rows\" or \"down columns\". Consider how df.dropna() or del df['col'] should be applied to most efficiently use the available non-missing data in your dataset and briefly answer the following questions in your own words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a6a557",
   "metadata": {},
   "source": [
    "1. Use Case for df.dropna()\n",
    "Example: Suppose you're working with a dataset containing customer feedback, and only a small portion of the dataset (e.g., 5% of rows) have missing values scattered across various columns. The rows with missing values may still contain useful data in other columns, and you don’t want to lose entire features.\n",
    "\n",
    "In this case, using df.dropna() is preferable because you only lose a few rows but retain all the columns, preserving the overall structure of the dataset for analysis.\n",
    "\n",
    "Reason: Dropping a few rows avoids discarding valuable columns that might provide important insights. If the missing data is sparse, row deletion is a less disruptive choice.\n",
    "2. Opposite Use Case for del df['col']\n",
    "Example: Imagine you are analyzing a dataset of medical records, and one of the columns, \"Patient Notes,\" contains 80% missing values. This column is not essential for your analysis, which focuses on numerical features like blood pressure, heart rate, and cholesterol levels.\n",
    "\n",
    "In this scenario, using del df['col'] to remove the \"Patient Notes\" column is preferable over df.dropna(). Keeping this column would lead to the loss of many rows, which would reduce the dataset significantly.\n",
    "\n",
    "Reason: If a single column has an overwhelming amount of missing data and is not central to the analysis, it's more efficient to delete the column rather than lose large portions of the dataset by dropping rows.\n",
    "3. Importance of Applying del df['col'] Before df.dropna()\n",
    "Applying del df['col'] first is essential when both methods are used together because it removes columns that have significant amounts of missing data before the row-level operations occur. If you apply df.dropna() first, it could result in the loss of many rows unnecessarily, which could have been avoided if columns with high missingness were removed first.\n",
    "\n",
    "Reason: By deleting columns with extensive missing data first, you prevent losing rows that still have valuable data in other columns. This maximizes the usable data while reducing the impact of missing values.\n",
    "4. Application of Missing Data Removal and Before/After Report\n",
    "Example Dataset: Suppose I have a dataset containing product reviews, with columns for \"Product ID,\" \"User ID,\" \"Rating,\" \"Review Text,\" and \"Review Date.\" Let's assume the \"Review Text\" column has 60% missing values and some rows are missing ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f59dd6",
   "metadata": {},
   "source": [
    "First, I will remove the \"Review Text\" column because the textual reviews are not crucial for this particular analysis, and it has a high percentage of missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d661bf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['Review Text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc98250",
   "metadata": {},
   "source": [
    "Next, I will use df.dropna() to remove any rows that have missing values in the remaining important columns (e.g., \"Rating,\" \"User ID\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fad7de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480585ed",
   "metadata": {},
   "source": [
    "Use your ChatBot session to understand what df.groupby(\"col1\")[\"col2\"].describe() does and then demonstrate and explain this using a different example from the \"titanic\" data set other than what the ChatBot automatically provide for you"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6c451a",
   "metadata": {},
   "source": [
    "The df.groupby(\"col1\")[\"col2\"].describe() method groups the data in the DataFrame df by the values in column col1, and then provides summary statistics (such as count, mean, std, min, etc.) for the column col2 within each group.\n",
    "\n",
    "Breakdown of the method:\n",
    "df.groupby(\"col1\"): Groups the DataFrame by the unique values in column col1. Each unique value in col1 forms a group, and the data is split accordingly.\n",
    "[\"col2\"]: Selects column col2 within each of the groups formed.\n",
    "describe(): Generates the summary statistics (count, mean, std, etc.) for column col2 within each group defined by col1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befc2515",
   "metadata": {},
   "source": [
    "Example Using Titanic Dataset\n",
    "Let’s say we have the Titanic dataset, and we want to group passengers by their \"Pclass\" (passenger class), and then get summary statistics for their \"Age\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d08bae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Titanic dataset\n",
    "import seaborn as sns\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "# Grouping by \"Pclass\" and describing the \"Age\" column\n",
    "titanic.groupby(\"pclass\")[\"age\"].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda8cd97",
   "metadata": {},
   "source": [
    "Explanation of the Example:\n",
    "titanic.groupby(\"pclass\"): This groups the Titanic passengers by their passenger class, which can be either 1, 2, or 3.\n",
    "[\"age\"]: From each passenger class group, we select the \"age\" column for analysis.\n",
    "describe(): This provides summary statistics for the \"age\" of passengers in each class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8747b24d",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "For Pclass 1 (first-class passengers), the average age is 38.23 years, with a standard deviation of 14.80 years. The youngest passenger in this class is 0.92 years old, and the oldest is 80 years old.\n",
    "For Pclass 2 (second-class passengers), the average age is 29.88 years, and for Pclass 3 (third-class passengers), it's 25.14 years.\n",
    "The table shows that first-class passengers tend to be older on average compared to second- and third-class passengers, as indicated by the higher mean age.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039977b1",
   "metadata": {},
   "source": [
    "ssuming you've not yet removed missing values in the manner of question \"7\" above, df.describe() would have different values in the count value for different data columns depending on the missingness present in the original data. Why do these capture something fundamentally different from the values in the count that result from doing something like df.groupby(\"col1\")[\"col2\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400dc522",
   "metadata": {},
   "source": [
    "1. df.describe() and Missing Values\n",
    "Purpose: This method provides summary statistics for each column across the entire dataset.\n",
    "Effect of Missing Data: The count value for each column in df.describe() reflects the number of non-missing values in that column.\n",
    "If a column has missing values (NaN), its count will be lower than the number of total rows in the dataset.\n",
    "For example, if a dataset has 100 rows and 10 of them have missing values in the \"age\" column, df.describe() will show count = 90 for \"age.\"\n",
    "Captures: This approach gives you a dataset-wide overview of the completeness of each column, showing how many non-missing values exist for each variable independently.\n",
    "2. df.groupby(\"col1\")[\"col2\"].describe() and Missing Values\n",
    "Purpose: This method groups the data by the values in col1 and then computes summary statistics for col2 within each group.\n",
    "Effect of Missing Data: When missing data is present, df.groupby(\"col1\")[\"col2\"].describe() will calculate the count for col2 within each group formed by the unique values of col1. The count reflects the number of non-missing values in col2 for each group separately.\n",
    "For instance, if grouping by \"Pclass\" and calculating statistics for \"Age,\" the count for each passenger class will reflect the number of non-missing ages within each class.\n",
    "Missing data in col1 (the grouping column) will lead to those rows being excluded entirely from the grouped analysis.\n",
    "Captures: The count here reflects how many valid (non-missing) values exist for col2 within each group of col1. This gives insight into how the completeness of the data differs across the groups (e.g., passenger classes).\n",
    "Key Differences:\n",
    "Scope of Analysis:\n",
    "df.describe() looks at the entire dataset and gives the count for each column independently of other columns.\n",
    "df.groupby(\"col1\")[\"col2\"].describe() focuses on the relationship between col1 and col2, providing group-specific statistics. It tells you how much valid data exists for col2 within each group defined by col1.\n",
    "Impact of Missing Data:\n",
    "In df.describe(), the count varies by column because of missing values in each column. It doesn't account for interrelationships between columns.\n",
    "In df.groupby(\"col1\")[\"col2\"].describe(), the count shows how many valid values exist in col2 for each unique value in col1. Missing values in either column may affect the group sizes and available data for calculating statistics.\n",
    "Example of How They Differ:\n",
    "Imagine the Titanic dataset where some passengers have missing \"Age\" values and we haven't yet removed missing data.\n",
    "\n",
    "df.describe():\n",
    "You will see a lower count for the \"Age\" column (e.g., 714 out of 891 passengers), but it will be the same for the entire dataset.\n",
    "df.groupby(\"Pclass\")[\"Age\"].describe():\n",
    "This will provide separate count values for \"Age\" for each passenger class (Pclass). For example, you might find that first-class passengers have 186 valid \"Age\" entries, second-class has 173, and third-class has 355. These counts will reflect how much valid data exists in each class specifically.\n",
    "In short, df.describe() provides a dataset-wide overview of completeness, while df.groupby(\"col1\")[\"col2\"].describe() shows how data completeness varies within groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba40da4",
   "metadata": {},
   "source": [
    "Forget to include import pandas as pd in your code\n",
    "Use Kernel->Restart from the notebook menu to restart the jupyter notebook session unload imported libraries and start over so you can create this error\n",
    "\n",
    "When python has an error, it sometimes provides a lot of \"stack trace\" output, but that's not usually very important for troubleshooting. For this problem for example, all you need to share with ChatGPT or search on google is \"NameError: name 'pd' is not defined\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c656f49",
   "metadata": {},
   "source": [
    "Open your Jupyter Notebook.\n",
    "In the code cell, try to execute something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c374fc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df38f01",
   "metadata": {},
   "source": [
    "Fixing the Error:\n",
    "You only need to import pandas with this simple line at the top of your notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bb0864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4326ff14",
   "metadata": {},
   "source": [
    "Important Part of the Stack Trace:\n",
    "As you mentioned, the full stack trace can be long and include many lines, but for most basic errors like this, the critical part is the NameError:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea8696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NameError: name 'pd' is not defined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f6185e",
   "metadata": {},
   "source": [
    "Mistype \"titanic.csv\" as \"titanics.csv\"\n",
    "If ChatBot troubleshooting is based on downloading the file, just replace the whole url with \"titanics.csv\" and try to troubleshoot the subsequent FileNotFoundError: [Errno 2] No such file or directory: 'titanics.csv' (assuming the file is indeed not present)\n",
    "\n",
    "Explore introducing typos into a couple other parts of the url and note the slightly different errors this produces\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810eff61",
   "metadata": {},
   "source": [
    "When you mistype the filename (e.g., \"titanics.csv\" instead of \"titanic.csv\") or introduce typos into other parts of the URL or file path, Python throws different errors depending on the nature of the mistake. Let’s troubleshoot these errors and see how they differ.\n",
    "\n",
    "1. Mistyping the Filename (titanics.csv)\n",
    "If you attempt to load the file using pandas with a mistyped filename:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83933b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('titanics.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba205ab8",
   "metadata": {},
   "source": [
    "Since \"titanics.csv\" doesn’t exist, you’ll encounter this error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25194db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FileNotFoundError: [Errno 2] No such file or directory: 'titanics.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9231eaf",
   "metadata": {},
   "source": [
    "Try to use a dataframe before it's been assigned into the variable\n",
    "You can simulate this by just misnaming the variable. For example, if you should write df.groupby(\"col1\")[\"col2\"].describe() based on how you loaded the data, then instead write DF.groupby(\"col1\")[\"col2\"].describe()\n",
    "\n",
    "Make sure you've fixed your file name so that's not the error any more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bbd7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.groupby(\"pclass\")[\"age\"].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caae29c",
   "metadata": {},
   "source": [
    "Since DF is not defined, this will raise the following error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0bd64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NameError: name 'DF' is not defined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa5c8a9",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "NameError: Python is telling you that it doesn't recognize DF because it hasn’t been defined anywhere in your code.\n",
    "This error occurs when Python encounters a variable name that hasn’t been initialized. In this case, you’ve loaded the data into df, but Python doesn't know what DF refers to.\n",
    "Fix:\n",
    "Correct the variable name back to the proper case (df in this case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07843aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"pclass\")[\"age\"].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4388c2",
   "metadata": {},
   "source": [
    "If you forget one of the parentheses in your code, such as leaving off the closing parenthesis in pd.read_csv(url) and writing it as pd.read_csv(url, Python will throw a SyntaxError because the code is incomplete and not properly formed.\n",
    "\n",
    "Scenario:\n",
    "Suppose you attempt to load a CSV file using pandas but forget to close the parentheses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8062ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('titanic.csv'  # Missing closing parenthesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fadcd",
   "metadata": {},
   "source": [
    "Python will raise this error:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c199f484",
   "metadata": {},
   "outputs": [],
   "source": [
    "SyntaxError: unexpected EOF while parsing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93460f1",
   "metadata": {},
   "source": [
    "Fix:\n",
    "Add the missing closing parenthesis to correct the syntax error:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "df = pd.read_csv('titanic.csv')  # Correct version\n",
    "Other Common Scenarios Where You Might Miss Parentheses:\n",
    "Forgetting a closing parenthesis for function calls:\n",
    "python\n",
    "Copy code\n",
    "df.groupby(\"pclass\")[\"age\"].describe(  # SyntaxError here\n",
    "Error: SyntaxError: unexpected EOF while parsing\n",
    "Forgetting parentheses when calling a method:\n",
    "python\n",
    "Copy code\n",
    "df.describe  # Missing parentheses for method call\n",
    "This won’t raise a SyntaxError but instead will simply return the method object itself, without executing it. You’d need to add parentheses:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "df.describe()  # Correct version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e667be9",
   "metadata": {},
   "source": [
    "Mistype one of the names of the chained functions with the code\n",
    "For example, try something like df.group_by(\"col1\")[\"col2\"].describe() and df.groupby(\"col1\")[\"col2\"].describle()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc1f6c0",
   "metadata": {},
   "source": [
    "Scenario 1: Mistyping groupby as group_by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0575144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.group_by(\"pclass\")[\"age\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bb212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AttributeError: 'DataFrame' object has no attribute 'group_by'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ada313",
   "metadata": {},
   "source": [
    "Fix:\n",
    "Correct the method name from group_by to groupby:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78e4dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"pclass\")[\"age\"].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006575d3",
   "metadata": {},
   "source": [
    "Use a column name that's not in your data for the groupby and column selection\n",
    "For example, try capitalizing the columns for example replacing \"sex\" with \"Sex\" in titanic_df.groupby(\"sex\")[\"age\"].describe(), and then instead introducing the same error of \"age\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed48eb0",
   "metadata": {},
   "source": [
    "When you use a column name that doesn’t exist in your DataFrame, Python will throw a KeyError, indicating that it cannot find the specified column.\n",
    "\n",
    "Let’s simulate two different scenarios: mistyping the column name in the groupby and in the column selection.\n",
    "\n",
    "Scenario 1: Mistyping the Column Name in groupby\n",
    "Let’s assume you're working with the Titanic dataset, and you mistype \"sex\" as \"Sex\" in the groupby function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df74314",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.groupby(\"Sex\")[\"age\"].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c890899",
   "metadata": {},
   "source": [
    "If \"Sex\" (with capital \"S\") is not a valid column in your DataFrame (since it’s likely named \"sex\" in lowercase), you’ll get the following error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de078209",
   "metadata": {},
   "outputs": [],
   "source": [
    "KeyError: 'Sex'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fca403e",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "KeyError: This error occurs when you try to access a key (or column, in this case) that does not exist in the DataFrame.\n",
    "The error message 'Sex' tells you that Python is looking for a column called \"Sex\", but the actual column is likely named \"sex\", which is case-sensitive in pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1e1e39",
   "metadata": {},
   "source": [
    "Fix:\n",
    "Correct the column name from \"Sex\" to the correct lowercase \"sex\":\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7966106",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.groupby(\"sex\")[\"age\"].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee722a4",
   "metadata": {},
   "source": [
    "Forget to put the column name as a string in quotes for the groupby and column selection, and see if the ChatBot and google are still as helpful as they were for the previous question\n",
    "For example, something like titanic_df.groupby(sex)[\"age\"].describe(), and then titanic_df.groupby(\"sex\")[age].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abac5135",
   "metadata": {},
   "source": [
    "Scenario 1: Forgetting to Put the Column Name in Quotes for groupby\n",
    "Suppose you write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dca0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.groupby(sex)[\"age\"].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916f378e",
   "metadata": {},
   "source": [
    "Here, Python will raise a NameError because it thinks sex is a variable, not a column in your DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76e92d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NameError: name 'sex' is not defined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb3628e",
   "metadata": {},
   "source": [
    "Fix:\n",
    "Put the column name \"sex\" in quotes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fa8af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.groupby(\"sex\")[\"age\"].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a551fc3f",
   "metadata": {},
   "source": [
    "Please give a summary of our discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abb9641",
   "metadata": {},
   "source": [
    "Here's a summary of our discussion:\n",
    "\n",
    "df.describe() Summary Statistics: We reviewed the key statistics provided by the describe() method such as count, mean, std, min, etc., and their meanings.\n",
    "Handling Missing Data (df.dropna() vs del df['col']):\n",
    "df.dropna() is preferred when you want to remove rows with missing values to preserve columns with valuable data.\n",
    "del df['col'] is used when an entire column has too many missing values, making it less useful to keep.\n",
    "When using both, deleting columns before dropping rows can ensure more data is preserved after cleaning.\n",
    "df.groupby(\"col1\")[\"col2\"].describe(): This method groups data by a column (col1) and provides summary statistics for another column (col2). We discussed examples using the Titanic dataset and how grouping by a column provides different insights compared to df.describe().\n",
    "Errors and Troubleshooting:\n",
    "NameError: When you use a DataFrame variable before assigning it, or when there is a typo in function names (df.group_by or df.describle), you will get a NameError or AttributeError.\n",
    "FileNotFoundError: When you misspell the file name or directory (titanics.csv instead of titanic.csv), Python throws this error.\n",
    "Forgetting Parentheses: Missing a closing parenthesis leads to a SyntaxError: unexpected EOF.\n",
    "Misnamed Column (KeyError): Mistyping or incorrectly capitalizing column names (e.g., \"Sex\" instead of \"sex\") results in a KeyError because the column name does not exist.\n",
    "Omitting Quotes Around Column Names: Forgetting to enclose column names in quotes for groupby or column selection (e.g., df.groupby(sex)) results in a NameError, as Python interprets it as a variable instead of a string.\n",
    "Each error gave useful insights on how Python and pandas handle missing or incorrectly referenced data, helping us troubleshoot and correct common mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609c1248",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/95ada41c-faaf-4390-9506-0d805a39fe88"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
